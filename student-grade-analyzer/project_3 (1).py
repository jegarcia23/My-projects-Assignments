# -*- coding: utf-8 -*-
"""Project 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xeKy3M9T6EWqnAicg68yeOJkDP7Cd-wg

#Project 3 - Units 3 & 4
####Due: Tuesday, May 13th at 11:59PM
####Late Due Date: Friday, May 16th at 11:59PM
***Before starting remember to make a copy of this file by clicking on the 'File' tab on the upper left corner, and click 'Save a copy in Drive'.***

##Overview
***This is a pair project. You may choose to work individually or in pairs (max 2 people) for this project. You must submit the sign up form if you'd like to work in pairs first by the specified deadline (see Blackboard). Otherwise, you will be assigned to work individually.***

For your third project, you will create a Data Statistics Analyzer that demonstrates your knowledge of file operations, statistical analysis, and data visualization. This program will allow users to analyze and visualize statistics from a domain of your choice - such as sports, academic grades, financial data, health metrics, or any other dataset that interests you.
Your program will:

1. Read data from external files (CSV and TXT)
2. Perform statistical analysis using pandas and NumPy
3. Create insightful visualizations using Matplotlib
4. Generate a comprehensive report of the findings

You'll have the freedom to choose which type of data you want to work with, allowing you to explore statistics in an area that interests you personally. The following are a couple of examples of possible data sets:

* Sports Statistics
* Academic performance
* Financial Data
* Book/Movie Reviews
* etc.

##Project Requirements
* Read data from at least one csv file **and** one txt file
* Write output data to at least one csv file **and** one txt file
* Use pandas for data manipulation and analysis in at least 3 different ways
* Use NumPy for statistical computations in at least 3 different ways
* Create at least 3 different types of data visualizations using Matplotlib
* Include error handling for file operations and user input, providing clear feedback
* Display clear instructions and feedback to users for program usage
* Generate a comprehensive analysis report saved as a new csv file
* **You must not hardcode your code. This means that your program should work for any csv/txt file data (corresponding to the expected data format you define, you may assume no invalid data format)** For grading, we will be creating our own versions of txt and csv files corresponding to your expected data format.

##Project Rules
You are allowed to use the following in your project:



* Everything from Unit 1 - 4 as seen in class
* All imported modules we have seen in class, including:
  * Turtle
  * Matplotlib
  * NumPy
  * Pandas
* In addition, you may also use the following libraries that we have not seen in class. **For any of the following libraries you use, you must provide citations for where you learned about these. These may be links, videos, and even screenshots of Gemini explaining these to you. Failure to include proper citation will result in receiving no credit for these modules.**
  * random
  * math
  * statistics
* Gemini as a tool to help explain concepts and debug.
  * **You are not allowed to use Gemini to write your code for you. Doing so is considered cheating and will result in a 0 and will be reported.**

You are not allowed to use any of the following in your project. Doing so will result in point deductions or an automatic 0 on your project, depending on the severity of use:

* Anything we have not seen in class. You will receive no credit (even if your program works) if you use any code, imported modules (other than those seen in class or listed above), or logic which we have not learned in class.

  * If you have prior coding experience or are interested in implementing things outside of class, ask the instructor first. Permission may be granted on a case-by-case basis, but only if you seek permission from the instructor (not the TAs) first.


* Any genAI tools other than Gemini.

##Part 1: Choose your focus (5%)
Your first step is to choose a specific domain for your statistical analysis. Think about which area interests you most and what kinds of insights you'd like to discover.
Brainstorm by writing down several ideas that come to mind while thinking about these questions:

* What type of data would you find most interesting to analyze?
* What specific questions would you like to answer through statistical analysis?
* What kinds of insights would be valuable to someone making decisions based on this data?
* What visualizations would help communicate the patterns and relationships in this data?

Then, narrow your ideas. Keep your scope in mind - you want your chosen focus to make it possible for you to meet Project Requirements while remaining manageable.

###Your Task
Choose one domain for your statistics analyzer and create a brief description of your chosen approach. The description should include:

1. The specific type of data you'll analyze
2. How you'll use both csv and txt files in your analysis
3. Key questions you'll answer through your analysis
4. The types of statistical methods you'll apply
5. What the final output to the user will be

**Example program description:**

 * "I will create a basketball statistics analyzer that looks at player performance. My program will read game stats (points, rebounds, assists) from CSV files and player notes from TXT files. It will calculate basic statistics like averages and identify top performers in different categories. The program will also look for keywords in the text files to find player strengths mentioned by coaches. The final output will include bar charts showing player stats and a summary of findings saved as a CSV file.'

###Write your answer to Part 1 below:

I will create an academic performance analyzer that examines student grades across multiple subjects. The program will read student scores from a CSV file and class information from a TXT file. Using the CSV data, it will calculate statistical measures such as average scores, variance, and grade distributions. The TXT file will provide context about the class, such as course name and instructor details.
Key Questions:
Who are the top-performing students based on average grades?

What is the overall performance trend in each subject?

How are letter grades distributed across the class?

Write your answer here

---

##Part 2: Plan your data processing and statistical methods (10%)
###Your Task
Identify where and how you will use file operations, pandas, and NumPy in your statistics analyzer. You must include at least three examples of pandas usage and three examples of NumPy usage.

For file operations, describe:

1. How you will read from both CSV and TXT files in your project
2. How you will process and combine data from these different file formats
3. What error handling you will implement for each file type
4. How you will export the final analysis report


For pandas operations, describe:

1. What data manipulation or statistical analysis you will perform
2. How each operation contributes to generating meaningful insights

For NumPy operations, describe:

1. What statistical computations you will perform
2. How these calculations enhance your analysis

**Example operations for a basketball statistics analyzer:**

```
File Operations:
1. Reading CSV: I will use pandas.read_csv() to read player performance statistics from CSV files containing numerical data like points, rebounds, and assists
2. Reading TXT: I will use file reading operations to process scouting reports or player notes stored in text files
3. Data Integration: I will combine the numerical statistics with the text-based insights to create a comprehensive analysis
4. Writing Output: I will generate a statistical summary (CSV)
5. Error Handling: I will implement try/except blocks for both file types to handle missing files, data inconsistencies, and formatting issues

Pandas Operations:
1. Data filtering: I will use Dataframe's loc/iloc to filter players who scored above a certain number of points to identify top performers
2. Data iterating: I will use iterrrows() to iterate over the player data in my dataframe
3. Data Merging: I will use pandas.merge() to combine player statistics from multiple games with player information from another file

NumPy Operations:
1. Statistical analysis: I will use np.mean to calculate average performance metrics
2. Statistical analysis: I will use np.std() to calculate the variability in performance metrics.
3. Statistical analysis: ...
```

File Operations:
Reading CSV:
I will use pandas.read_csv() to load student grades data from a CSV file containing columns like StudentID, Name, and scores for each subject (e.g., Math, English, Science). This structured format allows efficient manipulation and analysis.

Reading TXT:
I will open and read a TXT file containing class_info such as course name, instructor, and semester. This text data provides contextual information to accompany the numerical grades.

Data Integration:
The program will process the CSV data to compute statistical measures and combine these results with class info read from the TXT file. The text data will be displayed alongside analysis results in output reports.

Error Handling:
I will implement try-except blocks around file reading to handle cases such as missing files, permission errors, or unexpected content. The program will provide user-friendly error messages guiding corrective action.

Writing Output:
The final analysis, including student averages, assigned letter grades, and summary statistics, will be exported as a new CSV file. Additionally, a TXT summary report will be generated for human-readable insights.

Pandas Operations:
Data Selection and Filtering:
I will use DataFrame indexing (.loc[]) to select students or subjects meeting certain criteria (like students scoring above a threshold). This helps identify top performers or underperforming areas.

Iterating Rows:
Using iterrows(), I will loop through DataFrame rows to calculate custom statistics such as averages or assign letter grades on a per-student basis, facilitating row-wise analysis.

Aggregation and Grouping:
I will use aggregation functions like .mean() and .value_counts() to summarize data, such as computing average scores per subject or counting the distribution of letter grades across the class. These provide meaningful insights into class performance trends.

NumPy Operations:
Mean Calculation:
I will use np.mean() to compute precise average scores for each subject and overall student averages, providing a measure of central tendency.

Variance and Standard Deviation:
Using np.var() and np.std(), I will quantify variability in student scores to identify how consistent performance is within subjects or across the class.

Statistical Thresholding:
I will use NumPy to help determine thresholds for grade assignments (e.g., calculating score cutoffs based on standard deviations from the mean), adding a statistical basis for grading.

###Write your answer to Part 2 below:

Write your answer here.

---

##Part 3: Design your statistical visualizations (10%)
###Your Task
Plan how you will use Matplotlib to create visual representations of your statistical data. You must create at least three different types of visualizations that provide meaningful insights.
Describe:

1. The types of visualizations you will create (e.g., bar charts, box plots, scatter plots, line graphs)
2. What statistical data will be represented in each visualization
3. How these visualizations will help users understand patterns and relationships in the data
4. Any customization you plan to add (colors, labels,
annotations, etc.)

**Example visualization plan for a basketball statistics analyzer:**

```
Visualization 1: Player Statistics Bar Graph
- This visualization will be a bar graph comparing key performance metrics across different players
- Data represented: Average points, rebounds, and assists for each player
- Insights: Shows at a glance which players excel in different statistical categories
- Customization: Different colors for each statistic type, player names on x-axis.

Visualization 2: Performance Trend Line Graph
- This visualization will be a line graph showing a player's performance metrics over a series of games
- Data represented: Points scored plotted against game dates.
- Insights: Shows performance consistency, improvement or decline over time.
- Customization: Different colored lines for each player, markers at each data point, game dates on x-axis, points on y-axis.

Visualization 3:...
```

###Write your answer to Part 3 below:

Visualization 1: Average Scores Bar Chart

-Type: Bar chart

-Data Represented: Each student’s average score across all subjects

-Insights: Quickly shows which students are performing well or need improvement

Customization:

-Bars colored in light blue for clarity,students names are labeled on the x-axis
on the y-axis is labeles as 'Average Score"


Visualization 2: Grade Distribution Pie Chart

-Type: Pie chart

-Data Represented: Distribution of letter grades (A, B, C, D, F) across the class

-Insights: Visualizes the overall grade spread to assess class performance quality and difficulty level

Customization:

-Different pastel colors for each grade segment, labels showing grade categories around the pie

Visualization 3: Subject-wise Performance Line Graph

-Type: Line graph

-Data Represented: Average scores per subject (Math, English, Science) for the entire class

-Insights: Helps identify which subjects students perform best or worst in, guiding instructional focus

Customization:

-Purple line with circle markers for each subject point,x-axis is labeled with the subject names and y-axis is labeled as "Average Scores'

Write your answer here.

---

##Part 4: Extra Credit (10% Bonus)
###Your Task
**This part is optional and may be skipped if you do not wish to complete the extra credit.**

For extra credit, add two additional statistical analysis and corresponding visualizations that were **not** covered in class. You are encouraged to do some independent research for this part. You are also encouraged to use the `statistics` library.

**To receive the extra credit points, you must also incorporate this in your code. Completing Part 4 below will not guarantee the extra credit points if you do not actually code it out.**

Plan how you will use Matplotlib to create visual representations of your statistical data.

For each additional analysis, describe:

1. The type of visualizations you will create
2. What statistical data will be represented in each visualization
3. How you will be using `Numpy`, `Pandas`, `Matplotlib`, and/or `statistics` to incorporate your data analysis & visualization
4. Citation. Where did you learn this from? Provide a link or screenshots of Gemini which show where you learned this from.

**In order to receive the extra credit, you must implement two additional statistical analysis and corresponding visualizations. Implementing only one will not give you half the points.**

###Write your answer to Part 4 below:

Write your answer here.

---

##Part 5: Write your code (50%)

Next, refer to the planning you did in earlier parts and write the code that creates your program!

Make sure it works as intended by running multiple times using different user input each time.

In order to receive full credit, in addition to its functionality and the instructions from the Overview, Part 2-3, your code must also:

* Include descriptive comments all throughout explaining different lines
* Be organized in an easy-to-read and understand manner
* Use descriptive variable names - avoid using single/double-letter names for variables
* Have appropriate spacing - don't clutter your code, and don't have a bunch of blank lines throughout
* Have proper indentation
**Note on genAI usage:** You’re encouraged to use [Gemini](https://gemini.google.com/app) while writing
your code. For example, you may want to ask it to explain a concept related to your program, such as what operator to use to check if two values are equal. Or, if you find you have a syntax error, you could leverage Gemini as part of your debugging process.

###**You are not allowed to use Gemini to write your code for you. Doing so is considered cheating and will result in a 0 and will be reported.**

###Write your code below:
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load CSV file into pandas DataFrame
def load_scores(csv_filename):
    try:
        df = pd.read_csv(csv_filename)
        print("Loaded CSV file:", csv_filename)
        return df
    except:
        print("Failed to read", csv_filename)
        return None

# Load TXT class info as plain text
def load_class_info(txt_filename):
    try:
        f = open(txt_filename, "r")
        content = f.read()
        f.close()
        print("Loaded TXT file:", txt_filename)
        return content
    except:
        print("Failed to read", txt_filename)
        return None

# Calculate averages
def calculate_averages(df):
    averages = []
    for i in range(len(df)):
        total = df.iloc[i]["Math"] + df.iloc[i]["English"] + df.iloc[i]["Science"]
        avg = total / 3
        averages.append(avg)
    return averages

# Find index of max average
def find_top_student_index(averages):
    max_val = averages[0]
    max_idx = 0
    for i in range(1, len(averages)):
        if averages[i] > max_val:
            max_val = averages[i]
            max_idx = i
    return max_idx

# Calculate variance
def calculate_variance(numbers):
    total = 0
    for n in numbers:
        total += n
    mean = total / len(numbers)

    variance_total = 0
    for n in numbers:
        diff = n - mean
        variance_total += diff * diff
    variance = variance_total / len(numbers)
    return mean, variance

# Count grades
def count_grades(grades):
    counts = {}
    for g in grades:
        if g in counts:
            counts[g] = counts[g] + 1
        else:
            counts[g] = 1
    return counts

# Assign letter grades
def assign_grades(averages):
    grades = []
    for avg in averages:
        if avg >= 90:
            grades.append("A")
        elif avg >= 80:
            grades.append("B")
        elif avg >= 70:
            grades.append("C")
        elif avg >= 60:
            grades.append("D")
        else:
            grades.append("F")
    return grades

# Write report CSV file
def write_report_csv(df, averages, grades, filename="report.csv"):
    f = open(filename, "w")
    f.write("StudentID,Name,Math,English,Science,Average,Grade\n")
    for i in range(len(df)):
        line = str(df.iloc[i]["StudentID"]) + "," + \
               str(df.iloc[i]["Name"]) + "," + \
               str(df.iloc[i]["Math"]) + "," + \
               str(df.iloc[i]["English"]) + "," + \
               str(df.iloc[i]["Science"]) + "," + \
               str(round(averages[i],2)) + "," + \
               grades[i] + "\n"
        f.write(line)
    f.close()
    print("Saved report CSV:", filename)

# Write summary TXT file
def write_summary_txt(top_student, average, subject_stats, filename="summary.txt"):
    f = open(filename, "w")
    f.write("Top Student:\n")
    f.write("StudentID: " + str(top_student["StudentID"]) + "\n")
    f.write("Name: " + top_student["Name"] + "\n")
    f.write("Average Score: " + str(round(average,2)) + "\n\n")

    f.write("Subject Statistics:\n")
    for subject in subject_stats:
        mean = subject_stats[subject]["mean"]
        variance = subject_stats[subject]["variance"]
        std_dev = subject_stats[subject]["std_dev"]
        f.write(subject + ":\n")
        f.write("  Mean: " + str(round(mean,2)) + "\n")
        f.write("  Variance: " + str(round(variance,2)) + "\n")
        f.write("  Std Dev: " + str(round(std_dev,2)) + "\n\n")
    f.close()
    print("Saved summary TXT:", filename)

# Plot average scores bar chart
def plot_average_scores(names, averages):
    plt.bar(names, averages, color="skyblue")
    plt.xlabel("Students")
    plt.ylabel("Average Score")
    plt.title("Average Scores of Students")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig("avg_scores_bar.png")
    plt.close()

# Plot grade distribution pie chart
def plot_grade_distribution(grades):
    counts = count_grades(grades)
    labels = []
    sizes = []
    for key in counts:
        labels.append(key)
        sizes.append(counts[key])
    colors = ["#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3"]
    plt.pie(sizes, labels=labels, colors=colors[:len(labels)])
    plt.title("Grade Distribution")
    plt.savefig("grade_pie_chart.png")
    plt.close()

# Plot subject averages line chart
def plot_subject_averages(subject_stats):
    subjects = []
    means = []
    for subject in subject_stats:
        subjects.append(subject)
        means.append(subject_stats[subject]["mean"])
    plt.plot(subjects, means, marker='o', linestyle='-', color='purple')
    plt.xlabel("Subjects")
    plt.ylabel("Average Score")
    plt.title("Subject-wise Average Scores")
    plt.grid(True)
    plt.savefig("subject_line_plot.png")
    plt.close()

# Main Program
def main():
    print("Academic Performance Analyzer\n")

    df = load_scores("students_scores.csv")
    class_info = load_class_info("class_info.txt")  # changed here
    if df is None or class_info is None:
        print("Missing input files. Exiting.")
        return

    averages = calculate_averages(df)
    top_idx = find_top_student_index(averages)
    top_student = df.iloc[top_idx]

    grades = assign_grades(averages)

    # Calculate stats for each subject
    subject_stats = {}
    for subject in ["Math", "English", "Science"]:
        scores = df[subject].to_numpy()
        mean, variance = calculate_variance(scores)
        std_dev = variance ** 0.5
        subject_stats[subject] = {"mean": mean, "variance": variance, "std_dev": std_dev}

    write_report_csv(df, averages, grades)
    write_summary_txt(top_student, averages[top_idx], subject_stats)

    plot_average_scores(df["Name"].tolist(), averages)
    plot_grade_distribution(grades)
    plot_subject_averages(subject_stats)

    print("\nDone! Check output files.")

if __name__ == "__main__":
    main()

"""---

##Part 6: Explain your work (25%)

###Your Task
A final part of the project is to explain your work and demonstrate your understanding of the program you created.

You will share your explanation in a video walkthrough of your code followed by a demonstration of your code running.

Specifically, in your video, you must explain the following:

* The intended functionality of the program you decided to create and why you choose to create that program

* Your process and the steps you took to design and develop this program

* How the code executes in one of your most complex conditional statements

* The lessons you learned through this project

* How you used Gemini as a tool in your development of your project

* Provide a live demonstration of your code

The video must not be longer than 6 minutes. There is no minimum time required, as long as you discuss all of the points above.

***If working in pairs, both members must participate and speak in the video. If one member does not participate in the video, they will receive 0 points for this part.***

---

##Deliverables and Evaluation Criteria

You will be responsible for the following deliverables. The weighting of each component is indicated below.

###Part 1 (5%)

###Part 2 (10%)

###Part 3 (10%)

###Part 4 (10% bonus)

###Part 5 (50%)

###Part 6 (25%)

##What to Submit and Where
For Parts 1 - 5, submit a copy of this file on the Blackboard Project 3 Parts 1 - 5 submission, as well as a copy of your csv and txt input files.

To save a copy of this file on your computer, click on File > Download > Download .ipynb

**DISCLAIMER: YOU MUST SUBMIT A .ipynb OR .py FILE FOR PARTS 1 - 5 IN ORDER FOR YOUR PROJECT TO BE GRADED. WE WILL NOT ACCEPT LINKS. SUBMITTING A LINK WILL RESULT IN AN AUTOMATIC 0.**

**DISCLAIMER: YOU MUST ALSO SUBMIT YOUR CSV AND TXT FILES AS WELL TO RECEIVE FULL CREDIT SO THAT WE CAN RUN YOUR CODE. IF YOU DO NOT, WE WILL GRADE AS IS.**

For Part 6, submit your video on the Blackboard Project 3 Part 6 submission.
"""